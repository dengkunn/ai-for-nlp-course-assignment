{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`各位同学大家好，欢迎各位开始学习我们的人工智能课程。这门课程假设大家不具备机器学习和人工智能的知识，但是希望大家具备初级的Python编程能力。根据往期同学的实际反馈，我们课程的完结之后 能力能够超过80%的计算机人工智能/深度学习方向的硕士生的能力。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次作业的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 复现课堂代码\n",
    "\n",
    "在本部分，你需要参照我们给大家的GitHub地址里边的课堂代码，结合课堂内容，复现内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 请回答以下问题\n",
    "\n",
    "回答以下问题，并将问题发送至 mqgao@kaikeba.com中：\n",
    "```\n",
    "    2.1. what do you want to acquire in this course？\n",
    "    2.2. what problems do you want to solve？\n",
    "    2.3. what’s the advantages you have to finish you goal?\n",
    "    2.4. what’s the disadvantages you need to overcome to finish you goal?\n",
    "    2.5. How will you plan to study in this course period?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 如何提交\n",
    "代码 + 此 jupyter 相关，提交至自己的 github 中(**所以请务必把GitHub按照班主任要求录入在Trello中**)；\n",
    "第2问，请提交至mqgao@kaikeba.com邮箱。\n",
    "#### 4. 作业截止时间\n",
    "此次作业截止时间为 2019.7.6日"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 完成以下问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 特定行业的对话机器人；商品的智能推荐；人脸识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 共享自己的某些项目，以及查看他人的项目；Jupyter可以快速的做模型验证以及学习演示；Pycharm用于真正的生产开发"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:其实任何事件都有一定的概率，概率模型就是对事件发生的概率进行建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:比如情感分析，是按照概率来呈现一句话的positive或者negative情感的；再比如垃圾邮件分类，是否是垃圾邮件也可基于概率；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:世上的事没有完全绝对的，我们对事件是否发生与否只能说我们相信该事件有多大的发生概率；基于parsing或者pattern match的方式，我们不得不穷举所有的场景，而且场景还可能有变化，这样以来基于pattern match的方式的代码得发生改变；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:语言模型就是计算一个句子出现的概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:比如中英文句子的自动纠错，对话机器人生成的句子是否合理，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:一个句子是由很多的词汇组成的，1gram表示的是句子的概率与前后词的顺序无关，只与每个词在语料库中出现的频率有关；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:缺点：不能捕捉词序对句子概率的影响，不能更精确的反应一个句子出现的概率；优点：简单，计算量小，比如可以用于Naive Bayes文本分类；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:对相邻两个词进行条件概率统计建模；p(s) = p(w1|start) * p(w2|w1) * p(w3|w2) * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何生成句子是一个很经典的问题，从1940s开始，图灵提出机器智能的时候，就使用的是人类能不能流畅和计算机进行对话。和计算机对话的一个前提是，计算机能够生成语言。\n",
    "\n",
    "计算机如何能生成语言是一个经典但是又很复杂的问题。 我们课程上为大家介绍的是一种基于规则（Rule Based）的生成方法。该方法虽然提出的时间早，但是现在依然在很多地方能够大显身手。值得说明的是，现在很多很实用的算法，都是很久之前提出的，例如，二分查找提出与1940s, Dijstra算法提出于1960s 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在著名的电视剧，电影《西部世界》中，这些机器人们语言生成的方法就是使用的SyntaxTree生成语言的方法。\n",
    "\n",
    "> \n",
    ">\n",
    "\n",
    "![WstWorld](https://timgsa.baidu.com/timg?image&quality=80&size=b10000_10000&sec=1561818705&di=95ca9ff2ff37fcb88ae47b82c7079feb&src=http://s7.sinaimg.cn/mw690/006BKUGwzy75VK46FMi66&690)\n",
    "\n",
    "> \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，需要各位同学首先定义自己的语言。 大家可以先想一个应用场景，然后在这个场景下，定义语法。例如：\n",
    "\n",
    "在西部世界里，一个”人类“的语言可以定义为：\n",
    "``` \n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "一个“接待员”的语言可以定义为\n",
    "```\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请定义你自己的语法: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法：生成咨询保险问题的问句"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_question = '''\n",
    "sentence = 疑问词 动词 名词 | 名词 动词 疑问词 | 名词 疑问词 动词\n",
    "疑问词 = 什么 | 是否 | 如何 | 哪里 | 谁 | 多久 | 哪些 | 哪个 | 为什么\n",
    "动词 = 是 | 不是 | 买 | 购买 | 覆盖 | 获得 | 支付 | 涵盖 | 索赔\n",
    "名词 = 保险 | 人寿保险 | 汽车保险 | 医疗保险 | 保险公司 | 保险费 \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，使用自己之前定义的generate函数，使用此函数生成句子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "choice = random.choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grammer(grammer_str, split='='):\n",
    "    grammer = {}\n",
    "    for line in grammer_str.split('\\n'):\n",
    "        if not line: continue\n",
    "        exp, statement = line.split(split)\n",
    "        grammer[exp.strip()] = [s.split() for s in statement.split('|')]\n",
    "    return grammer    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(grammer, target='sentence'):\n",
    "    if target not in grammer: return target\n",
    "    \n",
    "    expanded = [generate_sentence(grammer, t) for t in choice(grammer[target])]\n",
    "    return ''.join(e for e in expanded if e != 'null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(grammer, target='sentence', count=100):\n",
    "    sentences = []\n",
    "    for i in range(count):\n",
    "        sentences.append(generate_sentence(grammer, target=target))\n",
    "    return sentences    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_grammer = create_grammer(insurance_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = generate_n(insurance_grammer, count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保险涵盖谁\n",
      "人寿保险不是哪个\n",
      "为什么覆盖保险公司\n",
      "是否是人寿保险\n",
      "哪些索赔人寿保险\n",
      "如何不是人寿保险\n",
      "医疗保险为什么索赔\n",
      "哪些涵盖人寿保险\n",
      "医疗保险是是否\n",
      "哪个购买保险费\n",
      "保险获得哪里\n",
      "哪个涵盖保险公司\n",
      "谁不是保险公司\n",
      "医疗保险索赔是否\n",
      "医疗保险哪里涵盖\n",
      "保险公司哪里覆盖\n",
      "是否是保险公司\n",
      "哪里购买医疗保险\n",
      "什么是汽车保险\n",
      "医疗保险购买谁\n"
     ]
    }
   ],
   "source": [
    "for s in sentences:\n",
    "    print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_grammer = create_grammer(host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "先生,您好我是65号,您需要耍一耍喝酒吗？\n",
      "您好我是1号,请问你要耍一耍打牌吗？\n",
      "你好我是7号,您需要耍一耍打牌吗？\n",
      "你好我是6号,您需要玩一玩赌博吗？\n",
      "你好我是8149299512号,您需要耍一耍赌博吗？\n",
      "您好我是9号,您需要耍一耍喝酒吗？\n",
      "你好我是453号,请问你要耍一耍打猎吗？\n",
      "您好我是9号,您需要玩一玩打猎吗？\n",
      "女士,您好我是2号,您需要耍一耍打牌吗？\n",
      "您好我是5号,您需要玩一玩喝酒吗？\n",
      "小朋友,你好我是12号,您需要玩一玩打猎吗？\n",
      "你好我是4号,您需要玩一玩赌博吗？\n",
      "女士,你好我是22号,您需要耍一耍喝酒吗？\n",
      "女士,您好我是4号,请问你要玩一玩打牌吗？\n",
      "你好我是26号,请问你要玩一玩打牌吗？\n",
      "女士,你好我是9号,您需要玩一玩打牌吗？\n",
      "小朋友,您好我是46号,请问你要玩一玩赌博吗？\n",
      "你好我是97号,您需要玩一玩赌博吗？\n",
      "你好我是86号,您需要玩一玩赌博吗？\n",
      "小朋友,您好我是5号,您需要耍一耍喝酒吗？\n"
     ]
    }
   ],
   "source": [
    "generate_n(host_grammer,target='host', count=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照我们上文中定义的`prob_2`函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "\n",
    "1. 下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "    + 可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + 可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. 修改代码，获得新的**2-gram**语言模型\n",
    "    + 进行文本清洗，获得所有的纯文本\n",
    "    + 将这些文本进行切词\n",
    "    + 送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 选用保险行业问询对话集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "insurance_file = '/home/dk/NLP_study_kkb/datasource/train.txt'\n",
    "\n",
    "insurance_sentence = []\n",
    "for line in open(insurance_file):   \n",
    "    line = line.split('++$++')[2]\n",
    "    line = ''.join(re.findall(u\"[\\u4e00-\\u9fa5\\w]+\", line.decode('utf-8')))\n",
    "    insurance_sentence.append(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "cut = jieba.cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.157 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "insurance_token = []\n",
    "for line in insurance_sentence:\n",
    "    insurance_token += cut(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defaultdic: 当单词不在dict中，返回0,方便后续语言模型的建立\n",
    "insurance_words_count = Counter(insurance_token)\n",
    "insurance_words_frequency = defaultdict(int)\n",
    "for word, count in insurance_words_count.iteritems():\n",
    "    insurance_words_frequency[word] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "#add k smoothing\n",
    "N = len(insurance_token)\n",
    "V = len(insurance_words_frequency)\n",
    "def insurance_prob_1(word, k=0.001):\n",
    "    if not isinstance(word, unicode):\n",
    "        word = word.decode('utf-8')\n",
    "    return (insurance_words_frequency[word] + k) / (N + k * V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_token_2gram = [''.join(insurance_token[i:i+2]) for i in range(N-2)]\n",
    "insurance_words_count_2 = Counter(insurance_token_2gram)\n",
    "insurance_words_frequency_2 = defaultdict(int)\n",
    "for word, frequency in insurance_words_count_2.iteritems():\n",
    "    insurance_words_frequency_2[word] = frequency   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add k smoothing\n",
    "def insurance_prob_2(w1, w2, k=0.001):\n",
    "    if not isinstance(w1, unicode):\n",
    "        w1 = w1.decode('utf-8')\n",
    "    if not isinstance(w2, unicode):\n",
    "        w2 = w2.decode('utf-8')\n",
    "    \n",
    "    return (insurance_words_frequency_2[w1 + w2] + k) / (insurance_words_frequency[w1] + k * V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_insurance_probability(sentence):\n",
    "    words = list(jieba.cut(sentence))\n",
    "    count = len(words)\n",
    "    \n",
    "    sentence_prob = 1\n",
    "    \n",
    "    for i, word in enumerate(words[0:-1]):\n",
    "        next_ = words[i+1]\n",
    "        prob = insurance_prob_2(word, next_)\n",
    "        sentence_prob *= prob\n",
    "    #print count    \n",
    "        \n",
    "    return sentence_prob * count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010977298440621152"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_insurance_probability(insurance_sentence[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示，要实现这个函数，你需要Python的sorted函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(): \n",
    "    sentences_prob = []\n",
    "    sentences = generate_n(insurance_grammer, count=20)\n",
    "    for s in sentences:\n",
    "        sentences_prob.append((s,get_insurance_probability(s)))\n",
    "    \n",
    "    sentences_prob = sorted(sentences_prob, key=lambda x : x[1], reverse=True)    \n",
    "    for sentence, prob in sentences_prob:\n",
    "        print sentence, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为什么购买汽车保险 0.00196291860782\n",
      "为什么是人寿保险 0.000678204532809\n",
      "汽车保险多久是 0.000183107645286\n",
      "人寿保险索赔是否 6.92028780106e-05\n",
      "医疗保险索赔为什么 2.932857593e-05\n",
      "哪些购买汽车保险 1.38594200267e-06\n",
      "医疗保险覆盖是否 2.68330142173e-07\n",
      "保险费哪个获得 2.47616695306e-07\n",
      "保险费购买为什么 8.1602725997e-08\n",
      "人寿保险支付哪里 5.09577369549e-08\n",
      "为什么涵盖汽车保险 4.6009723244e-08\n",
      "人寿保险是哪个 4.21641694902e-08\n",
      "保险什么获得 3.9256100538e-08\n",
      "汽车保险哪里支付 2.02128543052e-08\n",
      "汽车保险获得什么 8.64683353783e-09\n",
      "保险公司不是哪个 1.3870066637e-09\n",
      "保险费哪些索赔 2.88616553052e-10\n",
      "医疗保险哪里索赔 9.46654539271e-12\n",
      "什么买保险费 5.82957843958e-12\n",
      "什么支付保险 2.08787910547e-12\n"
     ]
    }
   ],
   "source": [
    "generate_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，现在我们实现了自己的第一个AI模型，这个模型能够生成比较接近于人类的语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 这个模型有什么问题？ 你准备如何提升？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以下内容为可选部分，对于绝大多数同学，能完成以上的项目已经很优秀了，下边的内容如果你还有精力可以试试，但不是必须的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (Optional) 完成基于Pattern Match的语句问答\n",
    "> 我们的GitHub仓库中，有一个assignment-01-optional-pattern-match，这个难度较大，感兴趣的同学可以挑战一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. (Optional) 完成阿兰图灵机器智能原始论文的阅读\n",
    "1. 请阅读阿兰图灵关于机器智能的原始论文：https://github.com/Computing-Intelligence/References/blob/master/AI%20%26%20Machine%20Learning/Computer%20Machinery%20and%20Intelligence.pdf \n",
    "2. 并按照GitHub仓库中的论文阅读模板，填写完毕后发送给我: mqgao@kaikeba.com 谢谢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各位同学，我们已经完成了自己的第一个AI模型，大家对人工智能可能已经有了一些感觉，人工智能的核心就是，我们如何设计一个模型、程序，在外部的输入变化的时候，我们的程序不变，依然能够解决问题。人工智能是一个很大的领域，目前大家所熟知的深度学习只是其中一小部分，之后也肯定会有更多的方法提出来，但是大家知道人工智能的目标，就知道了之后进步的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，希望大家对AI不要有恐惧感，这个并不难，大家加油！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561828422005&di=48d19c16afb6acc9180183a6116088ac&imgtype=0&src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201807%2F28%2F20180728150843_BECNF.thumb.224_0.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
